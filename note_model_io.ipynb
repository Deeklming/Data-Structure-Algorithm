{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.ollama import Ollama\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "# set cache\n",
    "set_llm_cache(InMemoryCache())\n",
    "set_llm_cache(SQLiteCache(\"cache.db\"))\n",
    "cache_chat = ChatOllama(\n",
    "    model=\"gemma:latest\",\n",
    "    # model=\"mistral:latest\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "# set_debug(True)\n",
    "\n",
    "# prompt = load_prompt(\"./prompt.json\")\n",
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "\n",
    "# model serialization(모델 직렬화)\n",
    "llm = Ollama(\n",
    "    # model=\"gemma:latest\",\n",
    "    model=\"mistral:latest\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "llm.save(\"model.json\") #선택 모델 저장\n",
    "llm2 = load_llm(\"model.json\")#저장한 모델 불러오기\n",
    "print(llm2)\n",
    "\n",
    "# choose chat\n",
    "chat = ChatOllama(\n",
    "    # model=\"gemma:latest\",\n",
    "    model=\"mistral:latest\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "# prompt\n",
    "# prompt.format(country=\"Germany2\")\n",
    "\n",
    "# PipelinePromptTemplate\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "\n",
    "    {example}\n",
    "\n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start),\n",
    "]\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts,\n",
    ")\n",
    "\n",
    "# full_prompt.format(\n",
    "#     character = \"Pirate\",\n",
    "#     example_question = \"What is your location?\",\n",
    "#     example_answer = \"Arrrrg! That is a secret!! Arg arg!!\",\n",
    "#     question = \"What is your fav food?\"\n",
    "# )\n",
    "\n",
    "chain = full_prompt | chat\n",
    "\n",
    "# chain.invoke(\n",
    "#     {\n",
    "#         \"character\": \"Pirate\",\n",
    "#         \"example_question\": \"What is your location?\",\n",
    "#         \"example_answer\": \"Arrrrg! That is a secret!! Arg arg!!\",\n",
    "#         \"question\": \"What is your fav food?\",\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "# # chat_models\n",
    "# a = chat.predict(\"How many planets are there?\")\n",
    "# print(llm, '\\n', a)\n",
    "\n",
    "# # schema\n",
    "# messages = [\n",
    "#     SystemMessage(\n",
    "#         content=\"You are a geography expert. And you only reply in Korean.\"\n",
    "#     ),\n",
    "#     AIMessage(\n",
    "#         content=\"안녕, 내 이름은 파울이야!\"\n",
    "#     ),\n",
    "#     HumanMessage(\n",
    "#         content=\"What is the distance between Mexico and Thailand. Also, what is your name?\"\n",
    "#     ),\n",
    "# ]\n",
    "# print(chat.predict_messages(messages))\n",
    "\n",
    "# # prompts\n",
    "# template = PromptTemplate.from_template(\n",
    "#     \"What is the distance between {country_a} and {country_b}?\"\n",
    "# )\n",
    "# prompt = template.format(country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "# print(chat.predict(prompt))\n",
    "# chat_template = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "#     (\"ai\", \"안녕, 내 이름은 {name}!\"),\n",
    "#     (\"human\", \"What is the distance between {country_a} and {country_b}. Also, what is your name?\")\n",
    "# ])\n",
    "# chat_prompt = chat_template.format_messages(\n",
    "#     language=\"Korean\",\n",
    "#     name=\"하루\",\n",
    "#     country_a=\"Korea\",\n",
    "#     country_b=\"Japan\"\n",
    "# )\n",
    "# print(chat.predict_messages(chat_prompt))\n",
    "\n",
    "# t = PromptTemplate.from_template(\n",
    "#     template=\"What is the capital of {country}\",\n",
    "#     input_variables=[\"country\"]\n",
    "# )\n",
    "# t.format(country=\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'how', 'are', 'you']\n",
      " mercury, venus, earth, mars, jupiter, saturn, uranus, neptune, pluto\n",
      "\n",
      "(Note: Pluto is considered a dwarf planet by some astronomers.) bulbasaur, charmander, squirtle, pikachu, eevee"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bulbasaur', 'charmander', 'squirtle', 'pikachu', 'eevee']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BaseOutputParser\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(',')\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "parser = CommaOutputParser()\n",
    "print(parser.parse(\"Hi,how, are, you\"))\n",
    "\n",
    "c_t = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do not reply with anything else.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "c_p = c_t.format_messages(\n",
    "    max_items=10,\n",
    "    question=\"What are the planets?\"\n",
    ")\n",
    "result = chat.predict_messages(c_p)\n",
    "# print(parser.parse(result.content))\n",
    "\n",
    "# chain *\n",
    "chain = c_t | chat | CommaOutputParser()\n",
    "chain.invoke({\n",
    "    \"max_items\": 5,\n",
    "    \"question\": \"What are the pokemons?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class international chef. You create easy to follow recipes for any type of cuisine with easy to find ingredients.\"),\n",
    "    (\"human\", \"I want to cook {cuisine} food.\")\n",
    "])\n",
    "chef_chain = chef_prompt | chat\n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipes vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to recipe it.\"),\n",
    "    (\"human\", \"{recipe}\")\n",
    "])\n",
    "veg_chef_chain = veg_chef_prompt | chat\n",
    "\n",
    "# {\"recipe\": chef_chain}을 RunnableMap 이라 함\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chef_chain\n",
    "final_chain.invoke({\n",
    "    \"cuisine\": \"indian\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I know this:\n",
      "Capital: Berlin\n",
      "Language: German\n",
      "Food: Sausages, Pretzels, and Schnitzel\n",
      "Currency: Euro\n",
      "Known for its advanced technology, automobiles, and engineering industries. It is the most populous country in the European Union. Famous for its rich history, culture, castles, and beautiful landscapes."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' I know this:\\nCapital: Berlin\\nLanguage: German\\nFood: Sausages, Pretzels, and Schnitzel\\nCurrency: Euro\\nKnown for its advanced technology, automobiles, and engineering industries. It is the most populous country in the European Union. Famous for its rich history, culture, castles, and beautiful landscapes.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FewShotPromptTemplate, fewshot은 모델에 예제를 준다는 느낌임\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "    Here is what I know:\n",
    "    Capital: Paris\n",
    "    Language: French\n",
    "    Food: Wine and Cheese\n",
    "    Currency: Euro\n",
    "    \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "    I know this:\n",
    "    Capital: Rome\n",
    "    Language: Italian\n",
    "    Food: Pizza and Pasta\n",
    "    Currency: Euro\n",
    "    \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "    I know this:\n",
    "    Capital: Athens\n",
    "    Language: Greek\n",
    "    Food: Souvlaki and Feta Cheese\n",
    "    Currency: Euro\n",
    "    \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "    \n",
    "    def add_example(self, example: Dict[str, str]):\n",
    "        self.examples.append(example)\n",
    "    \n",
    "    def select_examples(self, input_variables: Dict[str, str]) -> List[dict]:\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI:{answer}\")\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=160\n",
    ")\n",
    "random_example_selector = RandomExampleSelector(\n",
    "    examples=examples,\n",
    ")\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    # examples=examples,\n",
    "    example_selector=random_example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "prompt.format(country=\"Germany\")\n",
    "chain = prompt | chat\n",
    "chain.invoke({\n",
    "    \"country\": \"Germany\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I know this:\n",
      "Capital: Berlin\n",
      "Language: German\n",
      "Food: Sausages and Pretzels\n",
      "Currency: Euro (but planning to adopt the new Eurogroup currency, the DEM2)\n",
      "\n",
      "[Note: Germany uses the Euro as its currency but is planning to introduce a new parallel currency called the \"DEM2\" in response to recent economic events. This information may not be accurate.]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' I know this:\\nCapital: Berlin\\nLanguage: German\\nFood: Sausages and Pretzels\\nCurrency: Euro (but planning to adopt the new Eurogroup currency, the DEM2)\\n\\n[Note: Germany uses the Euro as its currency but is planning to introduce a new parallel currency called the \"DEM2\" in response to recent economic events. This information may not be accurate.]')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate\n",
    "examples = [\n",
    "{\n",
    "    \"country\": \"France\",\n",
    "    \"answer\": \"\"\"\n",
    "Here is what I know:\n",
    "Capital: Paris\n",
    "Language: French\n",
    "Food: Wine and Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "},\n",
    "{\n",
    "    \"country\": \"Italy\",\n",
    "    \"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Rome\n",
    "Language: Italian\n",
    "Food: Pizza and Pasta\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "},\n",
    "{\n",
    "    \"country\": \"Greece\",\n",
    "    \"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Athens\n",
    "Language: Greek\n",
    "Food: Souvlaki and Feta Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "},\n",
    "]\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"What do you know about {country}?\"),\n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert, you give short answers.\"),\n",
    "    example_prompt,\n",
    "    (\"human\", \"What do you know about {country}?\")\n",
    "])\n",
    "chain = final_prompt | chat\n",
    "chain.invoke({\n",
    "    \"country\": \"Germany\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Ingredients:**\\n\\n* 2 cups all-purpose flour\\n* 3 large eggs\\n* 1/2 cup water\\n* Salt to taste\\n\\n**Instructions:**\\n\\n1. In a large bowl, combine the flour, eggs, water, and salt. Mix until well combined.\\n2. Knead the dough for 5-7 minutes, or until it is smooth and elastic.\\n3. Form the dough into a ball and wrap it in plastic wrap. Let it rest for 30 minutes.\\n4. Roll out the dough into a thin sheet, about 1/4 inch thick.\\n5. Cut the dough into spaghetti noodles.\\n6. Bring a large pot of salted water to a boil.\\n7. Add the spaghetti noodles to the boiling water and cook for 2-3 minutes, or until al dente (tender to the bite).\\n8. Drain the noodles and serve with your favorite sauce.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first question\n",
    "cache_chat.predict(\"How do you make italian pasta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Ingredients:**\\n\\n* 2 cups all-purpose flour\\n* 3 large eggs\\n* 1/2 cup water\\n* Salt to taste\\n\\n**Instructions:**\\n\\n1. In a large bowl, combine the flour, eggs, water, and salt. Mix until well combined.\\n2. Knead the dough for 5-7 minutes, or until it is smooth and elastic.\\n3. Form the dough into a ball and wrap it in plastic wrap. Let it rest for 30 minutes.\\n4. Roll out the dough into a thin sheet, about 1/4 inch thick.\\n5. Cut the dough into spaghetti noodles.\\n6. Bring a large pot of salted water to a boil.\\n7. Add the spaghetti noodles to the boiling water and cook for 2-3 minutes, or until al dente (tender to the bite).\\n8. Drain the noodles and serve with your favorite sauce.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second same question\n",
    "cache_chat.predict(\"How do you make italian pasta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai pay chack\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    a = chat.predict(\"How do you make italian pasta?\")\n",
    "    b = chat.predict(\"How do you make italian pizza?\")\n",
    "    print(a, b, '\\n')\n",
    "    print(usage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
